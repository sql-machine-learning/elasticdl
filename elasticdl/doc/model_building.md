# ElasticDL Model Building
To submit an ElasticDL job, a user needs to provide a model file, such as [`mnist_functional_api.py`](../../model_zoo/mnist_functional_api/mnist_functional_api.py) used in this [example](elastic_scheduling.md#submit-the-first-job-with-low-priority).

This model file contains a [model](#model) built with TensorFlow Keras API and other components required by ElasticDL, including [dataset\_fn](#dataset_fn), [loss](#loss), [optimizer](#optimizer), and [metrics](#metrics), [call](#call), [get\_model](#get_model). Please refer to [interface](../model/abstract_model.py) for details.

## Model File Components
### model
`model` is a Keras model built using either TensorFlow Keras [functional API](https://www.tensorflow.org/guide/keras#functional_api) or [model subclassing](https://www.tensorflow.org/guide/keras#model_subclassing).

The following example shows a `model` using functional API, which has one input with shape (28, 28), and one putput with shape (10,):

```
from elastic.python.model import ElasticDLKerasBaseModel

class Model(ElasticDLKerasBaseModel):

    def __init__(self, context=None):
        super(Model, self).__init__(context=context)
        self._model = None

    def build_model(self):
        inputs = tf.keras.Input(shape=(28, 28), name='image')
        x = tf.keras.layers.Reshape((28, 28, 1))(inputs)
        x = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu')(x)
        x = tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu')(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)
        x = tf.keras.layers.Dropout(0.25)(x)
        x = tf.keras.layers.Flatten()(x)
        outputs = tf.keras.layers.Dense(10)(x)
        self._model = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist_model')

    def get_model(self):
        return self._model
model_inst = Model()
model = model_inst.get_model()
```

Another example using model subclassing:

```
from elastic.python.model import ElasticDLKerasBaseModel

class MnistModel(ElasticDLKerasBaseModel):
    def __init__(self):
        super(MnistModel, self).__init__(name='mnist_model')
        self._reshape = tf.keras.layers.Reshape((28, 28, 1))
        self._conv1 = tf.keras.layers.Conv2D(
            32, kernel_size=(3, 3), activation='relu')
        self._conv2 = tf.keras.layers.Conv2D(
            64, kernel_size=(3, 3), activation='relu')
        self._batch_norm = tf.keras.layers.BatchNormalization()
        self._maxpooling = tf.keras.layers.MaxPooling2D(
            pool_size=(2, 2))
        self._dropout = tf.keras.layers.Dropout(0.25)
        self._flatten = tf.keras.layers.Flatten()
        self._dense = tf.keras.layers.Dense(10)

    def call(self, inputs, training=False):
        x = self._reshape(inputs)
        x = self._conv1(x)
        x = self._conv2(x)
        x = self._batch_norm(x, training=training)
        x = self._maxpooling(x)
        if training:
            x = self._dropout(x, training=training)
        x = self._flatten(x)
        x = self._dense(x)
        return x

model_inst = MnistModel()
model = model_inst.get_model()
```
### dataset_fn

```
dataset_fn(dataset, training)
```
`dataset_fn` is a function that takes a RecordIO `dataset` as input, preprocesses the data as needed, and returns the a dataset containing `model_inputs` and `labels` as a pair.

Argument:

- dataset: a RecordIO dataset generated by ElasticDL. ElasticDL creates a dataset by iterating records from [RecordIO](https://github.com/wangkuiyi/recordio) file.
- mode: This can be any values in defined `from elasticdl.python.common.constants.Mode` representing different phases such as training
evaluation, and prediction. For example, if `mode == Mode.Prediction`, we don't need to return labels inside `_parse_data()`.

Output: a dataset, each data is a tuple (`model_inputs`, `labels`)

`model_inputs` is a dictionary of tensors, which will be used as [model](#model) input. `labels` will be used as an input argument in [loss](#loss).

Example:

```
def dataset_fn(dataset, mode):
    def _parse_data(record):
        if mode == Mode.PREDICTION:
            feature_description = {
                "image": tf.io.FixedLenFeature([28, 28], tf.float32)
            }
        else:
            feature_description = {
                "image": tf.io.FixedLenFeature([28, 28], tf.float32),
                "label": tf.io.FixedLenFeature([1], tf.int64),
            }
        r = tf.io.parse_single_example(record, feature_description)
        features = {
            "image": tf.math.divide(tf.cast(r["image"], tf.float32), 255.0)
        }
        if mode == Mode.PREDICTION:
            return features
        else:
            return features, tf.cast(r["label"], tf.int32)

    dataset = dataset.map(_parse_data)

    if mode != Mode.PREDICTION:
        dataset = dataset.shuffle(buffer_size=1024)
    return dataset
```

### loss
```
loss(self, outputs, labels)
```
`loss` is the loss function used in ElasticDL training.

Arguments:

- outputs:  [model](#model)'s output.

- labels: `labels` from [`dataset_fn`](#dataset_fn).

Example:

```
def loss(self, outputs, labels):
    return tf.reduce_mean(
        input_tensor=tf.nn.sparse_softmax_cross_entropy_with_logits(
            logits=outputs, labels=labels.flatten()
        )
    )
```

### optimizer
```
optimizer(self, lr=0.1)
```
`optimizer` is a function returns a [`tf.train.Optimizer`](https://www.tensorflow.org/api_docs/python/tf/train/Optimizer).

Example:

```
def optimizer(self, lr=0.1):
    return tf.optimizers.SGD(lr)
```

### metrics
```
def metrics(self,
            mode=Mode.TRAINING,
            outputs=None,
            predictions=None,
            labels=None)
```
`metrics` is a function that returns a dictionary where the key is name of the metric and the value
is the metric result from the `predictions` and `labels` , or `labels` using TensorFlow API. For example,
if mode equals `Mode.EVALUATION`, the returned metric dict is used to evaluate the model.

Example:

```
def metrics(self,
            mode=Mode.TRAINING,
            outputs=None,
            predictions=None,
            labels=None):
    if mode == Mode.EVALUATION:
        return {
            "accuracy": tf.reduce_mean(
            input_tensor=tf.cast(
                tf.equal(
                    tf.argmax(input=predictions, axis=1), labels.flatten()
                ),
                tf.float32,
            )
         )
        }
```

By default, it returns an empty dict.

### call

```
def call(self, inputs, training=False)
```

`call` returns the outputs of forward pass.

Arguments:

- inputs: inputs from dataset
- training: whether it is training or evaluation

### get_model

`get_model` returns the model instance created.
+ If users use [subclass]((https://www.tensorflow.org/guide/keras#model_subclassing), default
implementation can be used which returns `self`.
+ If users use [functional API](https://www.tensorflow.org/guide/keras#functional_api), the model
instance created should be returned.

### prepare_data_for_a_single_file
```
prepare_data_for_a_single_file(filename)
```
`prepare_data_for_a_single_file` is to read a single file and do whatever 
user-defined logic to prepare the data (e.g, IO from the user's file system, feature engineering), and return the serialized data. The function can be used to process data for training, evaluation and prediction. The only difference between prediction data with training/evaluation data is that the 'label' in prediction data should be empty. Users should be able to determine if the data file contains label (e.g, via the different formats of filename) and implement the logic to prepare the data accordingly.

Example:

```
def prepare_data_for_a_single_file(filename):
    '''
    An image classification dataset that images belonging to the same category located in the same directory.
    '''
    label = int(filename.split('/')[-2])
    image = PIL.Image.open(filename)
    numpy_image = np.array(image)
    example_dict = {
        "image": tf.train.Feature(
            float_list=tf.train.FloatList(value=numpy_image.flatten())
        ),
        "label": tf.train.Feature(
            int64_list=tf.train.Int64List(value=[label])
        ),
    }
    example = tf.train.Example(
        features=tf.train.Features(feature=example_dict)
    )
    return example.SerializeToString()
```


## Model Building Examples
### [MNIST model using Keras functional API](../../model_zoo/mnist_functional_api/mnist_functional_api.py)
### [MNIST model using Keras model subclassing](../../model_zoo/mnist_subclass/mnist_subclass.py)
### [CIFAR10 model using Keras functional API](../../model_zoo/cifar10_functional_api/cifar10_functional_api.py)
### [CIFAR10 model using Keras model subclassing](../../model_zoo/cifar10_subclass/cifar10_subclass.py)
