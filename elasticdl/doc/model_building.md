# ElasticDL Model Building
To submit an ElasticDL job, a user needs to provide a model file, such as [`mnist_functional_api.py`](../python/examples/mnist_functional_api.py) used in this [example](elastic_scheduling.md#submit-the-first-job-with-low-priority). 

This model file contains a [model](#model) built with Tensorflow Keras API and other components required by ElasticDL, including [input\_fn](#input_fn), [feature\_columns](#feature_columns), [label\_columns](#label_columns), [loss](#loss), [optimizer](#optimizer), and [eval_metrics_fn](#eval\_metrics\_fn). 

## Model File Components
### model
`model` is a Keras model built using either Tensorflow Keras [functional API](https://www.tensorflow.org/guide/keras#functional_api) or [model subclassing](https://www.tensorflow.org/guide/keras#model_subclassing).

The following example shows a `model` using functional API, which has one input with shape (28, 28), and one putput with shape (10,):

```
inputs = tf.keras.Input(shape=(28, 28), name='img')
x = tf.keras.layers.Reshape((28, 28, 1))(inputs)
x = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu')(x)
x = tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu')(x)
x = tf.keras.layers.BatchNormalization()(x, training=True)
x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)
x = tf.keras.layers.Dropout(0.25)(x, training=True)
x = tf.keras.layers.Flatten()(x)
outputs = tf.keras.layers.Dense(10)(x)

model = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist_model')
```

Another example using model subclassing:

```
class MnistModel(tf.keras.Model):
    def __init__(self):
        super(MnistModel, self).__init__(name='mnist_model')
        self._reshape = tf.keras.layers.Reshape((28, 28, 1))
        self._conv1 = tf.keras.layers.Conv2D(
            32, kernel_size=(3, 3), activation='relu')
        self._conv2 = tf.keras.layers.Conv2D(
            64, kernel_size=(3, 3), activation='relu')
        self._batch_norm = tf.keras.layers.BatchNormalization()
        self._maxpooling = tf.keras.layers.MaxPooling2D(
            pool_size=(2, 2))
        self._dropout = tf.keras.layers.Dropout(0.25)
        self._flatten = tf.keras.layers.Flatten()
        self._dense = tf.keras.layers.Dense(10)

    def call(self, inputs, training=False):
        x = self._reshape(inputs)
        x = self._conv1(x)
        x = self._conv2(x)
        x = self._batch_norm(x, training=training)
        x = self._maxpooling(x)
        if training:
            x = self._dropout(x, training=training)
        x = self._flatten(x)
        x = self._dense(x)
        return x

model = MnistModel()
```
### input_fn

```
input_fn(records)
```
`input_fn` is a function that takes a batch of training data `records` as input, preprocesses `records` as needed, and returns the batched `model_inputs` and `labels` as a pair.

Argument:

- records: a list of training data generated by ElasticDL. ElasticDL reads and decodes a batch of data from [RecordIO](https://github.com/wangkuiyi/recordio) file.

Output: a tuple (`model_inputs`, `labels`)

`model_inputs` is a dictionary of tensors, which will be used as [model](#model) input by applying the schema specified by [`feature_columns`](#feature_columns). `labels` will be used as an input argument in [loss](#loss).

Example:

```
def input_fn(records):
    image_list = []
    label_list = []
    # data processing
    for r in records:
        label = r['label']
        image /= 255
        label = label.astype(np.int32)
        image_list.append(image)
        label_list.append(label)

    # batching
    batch_size = len(image_list)
    images = np.concatenate(image_list, axis=0)
    images = np.reshape(images, (batch_size, 28, 28))
    labels = np.array(label_list)
    return ({'image': images}, labels)
```

### feature_columns
```
feature_columns()
```

`feature_columns` returns a list of [`tf.feature_column.numeric_column`](https://www.tensorflow.org/api_docs/python/tf/feature_column/numeric_column). 

The number of `tf.feature_column.numeric_column` in the list equals the number of [`model`](#model)'s inputs. `feature_columns` defines the schema between `model_input` from [`input_fn`]($input_fn)'s output and [model](#model)'s inputs.

The required arguments in `tf.feature_column.numeric_column` are `key`, `dtype`, and `shape`.

`feature_columns` is also used for encoding and decoding the training data in RecordIO file. This requires that [`input_fn`]($input_fn) cannot change the training data type and shape in data processing. This limitation will be addressed later in ElasticDL development.

For example, the following `feature_columns` example specifies that `model` has one input, which is `model_inputs['image']`, with data type as `tf.dtypes.float32` and shape as `[28, 28]`.

```
def feature_columns():
    return [tf.feature_column.numeric_column(key="image",
        dtype=tf.dtypes.float32, shape=[28, 28])]
```

### label_columns
```
label_columns()
```

`label_columns` returns a list of [`tf.feature_column.numeric_column`](https://www.tensorflow.org/api_docs/python/tf/feature_column/numeric_column), which is used for encoding and decoding the label data in RecordIO file.

Example:

```
def label_columns():
    return [tf.feature_column.numeric_column(key="label",
        dtype=tf.dtypes.int64, shape=[1])]
```

### loss
```
loss(output, labels)
```
`loss` is the loss function used in ElasticDL training.

Arguments:

- output:  [model](#model)'s output.

- labels: `labels` from [`input_fn`](#input_fn).

Example:

```
def loss(output, labels):
    return tf.reduce_mean(
        tf.nn.sparse_softmax_cross_entropy_with_logits(
            logits=output, labels=labels))
```

### optimizer
```
optimizer()
```
`optimizer` is a function returns a [`tf.train.Optimizer`](https://www.tensorflow.org/api_docs/python/tf/train/Optimizer).

Example:

```
def optimizer(lr=0.1):
    return tf.train.GradientDescentOptimizer(lr)
```

### eval_metrics_fn
```
eval_metrics_fn()
```
`eval_metrics_fn` is a function that returns a dictionary where the key is name of the evaluation metric and the value
is the evaluation metric result from the `predictions` and `labels` using TensorFlow API.

Example:

```
def eval_metrics_fn(predictions, labels):
    return {
        'metric': tf.reduce_mean(
            tf.nn.sparse_softmax_cross_entropy_with_logits(
                logits=predictions, labels=labels.flatten())),
    }
```

### prepare_data_for_a_single_file
```
prepare_data_for_a_single_file(filename)
```
`prepare_data_for_a_single_file` is to read a single file and do whatever 
user-defined logic to prepare the data (e.g, IO from the user's file system, feature engineering), and return a tuple of numpy array, which should be compatible with the feature and label columns above.

Example:

```
def prepare_data_for_a_single_file(filename):
    '''
    An image classification dataset that images belonging to the same category located in the same directory.
    '''
    label = int(filename.split('/')[-2])
    image = PIL.Image.open(filename)
    numpy_image = np.array(image)
    return numpy_image, label
```


## Model Building Examples
### [MNIST model using Keras functional API](../python/examples/mnist_functional_api.py)
### [MNIST model using Keras model subclassing](../python/examples/mnist_sublcass.py)
