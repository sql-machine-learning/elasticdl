## Targeted Users

ElasticDL targets two categories of users

1. *Modelers*, those who create new models, including deep learning researchers and engineers, and
1. SQLFlow users.

The high-level API must meet the requirements of these users.

## User Expectations

### Modelers

Modelers usually craft their Keras models on their personal computers, test the model with small datasets, and would like to file a distributed training job with big datasets on the cloud.

Suppose that one is working on a model in the local directory `$HOME/work/fintech/*.py`, where each `.py` file might contain one ore more Keras model classes. We would love to allow the user to submit an ElasticDL training job from the command-line like the following to train a model defined as a class `MyKerasModel`.

```bash
elasticdl train \
    --model_zoo=$HOME/work \
    --model_def=fintech.MyKerasModel \
    --input_fn=fintech.credit_data_processor \
    --params="hidden_units=[10, 100, 20, 5], learning_rate=0.01" \
    --data="gs://bucket-name/tony/imagenet/train/*.recordio" \
    --output="gs://bucket-name/tony/my_trained_model"
```

The above command-line 

1. builds a Docker image containing (1) `$HOME/work` mapped to `/model_zoo/custom`, (2) ElasticDL, (3) dependencies of ElasticDL,
1. submits an ElasticDL job to the Kubernetes cluster as described in `$HOME/.kube/config`,
1. prints an URL to the dashboard so users could inspect the progress/status of the job in the user's Web browser.


Because the above example command line specifies `--input_fn` explicitly, the training job is not going to use `MyKerasModel.default_input`, but uses `fintech.credit_data_processor`.  Similarly, command line options `loss` and `optimizer` overwrites `MyKerasModel.default_loss` and `MyKerasModel.default_optimizer`.

Another important command-line is to support prediction.

```bash
elasticdl predict \
    --data="gs://bucket-name/tony/imagenet/test/*.recordio" \
    --trained_model="gs://bucket-name/tony/my_trained_model" \
    --output="gs://bucket-name/tony/imagenet-eval/"
```

### SQLFlow Users

SQLFlow users provide the information required by training or prediction by writing a SQL statement with extended syntax.  The syntax for training extends the SELECT statement with the TRAIN clause.  For example:

```sql
SELECT name, role, salary FROM employee 
TRAIN regressor.DNN
WITH hidden_units=[10, 100, 20, 5], learning_rate=0.01
INTO my_trained_model;
```

Please be aware that to minimize the syntax extension, SQLFlow doesn't allow users to specify a directory of models; instead, users can only use pre-built models -- `regressor.DNN` in the above example.

SQLFlow is a gRPC server that takes the above SQL statement and translates it into a Python program known as a *submitter*.  It is the responsibility of the submitter to call `kubectl` to launch an ElasticDL job on a Kubernetes cluster.

SQLFlow often runs in Docker containers, and it is usually intractable to build a Docker image from within a Docker container, so the submitter requires a pre-built Docker image containing (1) `/model_zoo`, (2) ElasticDL, (3) dependencies of ElasticDL.  The class `regressor.DNN` is a class defined in some Python source files in `/model_zoo`.

The submitter might file the statement `SELECT name, role, salary FROM employee` to the SQL engine, pull the result, convert the result into one or more RecordIO files whose each record is a serialization of the `tf.Example` protobuf message. So, the input function used by ElasticDL to parse the strings for `DNNClassifer.class` could be standardized one, say, `sqlflow.elasticdl_input_function`.

To predict using a pre-trained model and to write the results into a column of a table, we can do

```sql
SELECT name, role FROM testdata
PREDICT testdata.predicted_salary
USING my_trained_model;
```

### Unified API

Both the command line tool `elasticdl` provided for modelers and the submitter program generated by SQLFlow need to call an API that launches ElasticDL jobs.  Hence this design.

## API

We hope the ElasticDL API supports not only batch learning, but also online learning, adversarial learning, reinforcement learning, and federated learning.  However, at the right moment, let us start with batch learning.


### Model building phase

ElasticDL supports Keras models built using either TensorFlow Keras [functional API](https://www.tensorflow.org/guide/keras#functional_api)
or [model subclassing](https://www.tensorflow.org/guide/keras#model_subclassing). In order to train models, ElasticDL requires users to provide
a `ElasticDLSpec`. The `ElasticDLSpec` tells ElasticDL how to create model, optimizer, loss, dataset and metrics.

Please refer to [model\_building](./model_building.md) for detailed explaination of each function.

```python
from elasticdl.python.common.constants import Mode

class ElasticDLSpec(object):
    def __init__(self, context=None):
        """
        Args: context: a dict of contextual information from ElasticDL,
                             such as worker_id, master ip.
        """
        self._context = context

    @abstractmethod
    def create_optimizer(self, lr=0.1):
        """returns a tensorflow optimizer such as `tf.train.GradientDescentOptimizer`"""
         pass

    @abstractmethod
    def create_loss(self, outputs=None, labels=None):
        """returns a tensor represents loss using outputs and labels"""
        pass

    @abstractmethod
    def create_metrics(self,
                       mode=Mode.TRAINING,
                       outputs=None,
                       labels=None,
                       predictions=None,):
        """returns a dict of metrics"""
        pass

    @abstractmethod
    def create_model(self):
        """returns the model created
        Users can use functional API or subclass to create customized Keras model.
        """
        pass

    @abstractmethod
    def create_dataset(self, dataset, mode):
        """returns a `tf.data.Dataset`"""
        pass
```

For example, we want to train a model on mnist dataset. We need to provide a similar
`ElasticDLSpec` to ElasticDL. Let's call it `MnistElasticDLSpec`.

```python

class MnistElasticDLSpec(ElasticDLSpec):

    def __init__(self, context=None, **kwargs):
        super(MnistElasticDLSpec, self).__init__(context=context)

    def create_optimizer(self, lr=0.1):
        return tf.train.GradientDescentOptimizer(learning_rate=lr)

    def create_loss(self, outputs=None, labels=None):
        labels = tf.reshape(labels, [-1])
        return tf.reduce_mean(
            input_tensor=tf.nn.sparse_softmax_cross_entropy_with_logits(
                logits=output, labels=labels
            )
        )

    def create_model(self):
        """returns the model instance
        We can use either functional API or Keras model subclass to create the model
        """
        inputs = tf.keras.Input(shape=(28, 28), name="image")
        x = tf.keras.layers.Reshape((28, 28, 1))(inputs)
        x = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation="relu")(x)
        x = tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation="relu")(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)
        x = tf.keras.layers.Dropout(0.25)(x)
        x = tf.keras.layers.Flatten()(x)
        outputs = tf.keras.layers.Dense(10)(x)
        return tf.keras.Model(inputs=inputs, outputs=outputs, name="mnist_model")

    def create_metrics(self,
                mode=Mode.TRAINING,
                outputs=None,
                labels=None):

        if mode == Mode.EVALUATION:
            labels = tf.reshape(labels, [-1])
            return {
            "accuracy": tf.reduce_mean(
                    input_tensor=tf.cast(
                    tf.equal(
                        tf.argmax(outputs, 1, output_type=tf.dtypes.int32),
                        labels,),
                    tf.float32,)
                    )
            }
        return {}

    def create_dataset(self, dataset, mode):
        def _parse_data(record):
            if mode == Mode.PREDICTION:
                feature_description = {
                "image": tf.io.FixedLenFeature([28, 28], tf.float32)
            }
            else:
                feature_description = {
                    "image": tf.io.FixedLenFeature([28, 28], tf.float32),
                    "label": tf.io.FixedLenFeature([1], tf.int64),
                }
            r = tf.io.parse_single_example(record, feature_description)
            features = {
                "image": tf.math.divide(tf.cast(r["image"], tf.float32), 255.0)
            }
            if mode == Mode.PREDICTION:
                return features
            else:
                return features, tf.cast(r["label"], tf.int32)

        dataset = dataset.map(_parse_data)

        if mode != Mode.PREDICTION:
            dataset = dataset.shuffle(buffer_size=1024)
        return dataset

```

+ Constructor will receive a keyword parameter `context`, which will contain environment information.
  + Currently it is None.
+ `**kwargs` are the parameters from `model_params` argument.
+ `create_metrics` function should return specified metrics according to mode. By default, it returns an empty dict.

Users can refer to [model\_zoo](/elasticdl/model_zoo) for more examples.

### For Training

We propose a function `elastic.train` that can be called like the following:

```python
elasticdl.train(
    model_zoo="$HOME/work",
    model_def="fintech.MyKerasModel", 
    input_fn="fintech.credit_data_processor",
    params="hidden_units=[10, 100, 20, 5], learning_rate=0.01",
    data="gs://bucket-name/tony/imagenet/train/*.recordio",
    output="gs://bucket-name/tony/my_trained_model")
```

or

```python
elasticdl.train(
    model_zoo="https://github.com/sql-machine-learning/models",
    model_def="regressor.DNN", 
    input_fn="sqlflow.elasticdl_input_function',
    params="hidden_units=[10, 100, 20, 5], learning_rate=0.01",
    data="gs://sqlflow/job-xxyyzz/train/*.recordio",
    output="gs://sqlflow/job-xxyyzz/my_trained_model")
```

Please be aware that most parameters of `elasticdl.train` are of string-type because the command line options and SQL statements are all strings.

### For Prediction

We propose a function `elasticdl.predict` that can be called like the following:

```python
elasticdl.predict(
    data='gs://bucket-name/tony/imagenet/test/*.recordio',
    trained_model='gs://bucket-name/tony/my_trained_model',
    output='gs://bucket-name/tony/imagenet-eval.recordio')
```

or

```python
elasticdl.predict(
    data="gs://sqlflow/job-xxyyzz/predict/*.recordio",
    trained_model='gs://sqlflow/job-xxyyzz/my_trained_model,
    output="gs://sqlflow/job-xxyyzz/predicted/")
```

## Model Zoo

When the ElasticDL client or the SQLFlow server call `elasticdl.train`, this function calls Docker API to build a Docker image then submits the job.  The building process should add a *model zoo* into the Docker image.  The function `elasticdl.train` has a parameter, which could be the following cases:

1. A local directory, for example,

   ```python
   elasticdl.train(model_zoo="a_local_directory", ...)
   ```
   
1. A URL pointing to a Git repo

   ```python
   elasticdl.train(model_zoo="https://git.company.com/sql-machine-learning/models", ...)
   ```

A model zoo is a plain Python source directory that's added to `/model_zoo` in the Docker image.  In the root directory there requires a `requirements.txt` file, so the image building process can install dependencies via

```dockerfile
RUN pip install -r /model_zoo/requirements.txt
```

Suppose that a Keras model class is referred to as `regressor.DNN` in `elasticdl.train(model_def="regressor.DNN",`, the corresponding Python file should be `/model_zoo/regressor.py`.  A class `regressor.wide_and_deep.MagicalWAD` is in a Python file `/model_zoo/regressor/wide_and_deep.py`.

## Trained Model

A call to `elasticdl.predict` looks like the following:

```python
elasticdl.predict(
    data='/filestore/yiwang/imagenet/test/*.recordio',
    trained_model='/filestore/tony/my_keras_model',
    output='/filestore/yiwang/imagenet-eval.recordio')
```

It needs to

1. build and push a Docker image, and
1. launch a distributed ElasticDL job of the type "predict".

The Docker image must contain the model zoo used to train the model `trained_model='/filestore/tony/my_keras_model'`.

A key question is what information must be in the directory `/filestore/tony/my_keras_model`.

1. A Docker image ID.

   We need this ID to refer to the Docker image built during the call of `elasticdl.train`.  In this image, we have the model zoo used to train the model.  Then, `elasticdl.predict` could build the Docker image for the distributed prediction job from this commit ID.

   This image ID must be a pullable ID so that ElasticDL command line tool can `docker pull` it as the base image. An example pullable ID is `docker-pullable://reg.docker.alibaba-inc.com/asdi/aswf-py3@sha256:e8ca09705eed07cdfd060b6b9d27a802`.

1. Model parameters as a map from parameter name to parameter value tensors, defined in [`elasticdl.proto`](https://github.com/wangkuiyi/elasticdl/blob/e06618af50cc9507e0b59473f4b97c066fa04870/elasticdl/proto/elasticdl.proto#L51-L54).

 
We define a new wrapper message:

```protobuf
message TrainedModel {
    string docker_commit_id = 1;
    string model_def = 2;
    string model_def_params = 3;
    string params_filename = 4;
    string input_function = 5;
    string loss = 6;
    string optimizer = 7;
}
```
